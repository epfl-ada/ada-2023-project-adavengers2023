{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2eb206a-5d90-4b9a-875f-bdfe21608c7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import Word2Vec\n",
    "import gensim\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68346385-dd3f-442e-82eb-161864fced02",
   "metadata": {},
   "source": [
    "The first step we are going to follow is to extract the character names to then be able to change them to the gender of the character. For now we just take the whole character dataset and replace it in the summaries. However this can lead to error for example in the summary used as example the word different  is counted as a male character and is replaced by he while in this context it's not a male character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2334fbeb-654a-466e-931b-715d0f51668e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# character name\n",
    "# use the data of character name & gender\n",
    "df = pd.read_csv('data/character.metadata.tsv', sep='\\t', header=None)\n",
    "name_list = df.iloc[:, [3]].dropna()\n",
    "df_name_gender = df.iloc[:, [3, 5]].dropna()\n",
    "df_name_gender.columns = ['Name','Gender']\n",
    "df_female_name = df_name_gender[df_name_gender['Gender']=='F']['Name']\n",
    "df_male_name = df_name_gender[df_name_gender['Gender']=='M']['Name']\n",
    "name_list=name_list.squeeze().tolist()\n",
    "name_dict = set()\n",
    "\n",
    "# build a name dict\n",
    "for item in list(name_list):\n",
    "    names = item.split()\n",
    "    for name in names:\n",
    "        # remove the names like 'Alice's father' that can have a negative impact on the result\n",
    "            name_dict.add(name.lower())\n",
    "\n",
    "cleaned_list = [re.sub('[^a-zA-Z]', '', s) for s in name_dict]\n",
    "with open('data/names from movies.txt', 'w', encoding='utf-8') as file:\n",
    "    for item in cleaned_list:\n",
    "        file.write(item + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c493a542-5113-456a-a159-26c2e4486983",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of female name dict before:26452\n",
      "length of female name dict after:15520\n"
     ]
    }
   ],
   "source": [
    "# create a set to collect the names of female and male characters\n",
    "female_name_dict = set()\n",
    "male_name_dict = set()\n",
    "\n",
    "# build a name dict\n",
    "for item in df_female_name:\n",
    "    names = item.split()\n",
    "    for name in names:\n",
    "        # remove the names like 'Alice's father' that can have a negative impact on the result\n",
    "        if not name.lower().endswith(\"'s\"):\n",
    "            female_name_dict.add(name.lower())\n",
    "for item in df_male_name:\n",
    "    names = item.split()\n",
    "    for name in names:\n",
    "        if not name.lower().endswith(\"'s\"):\n",
    "            male_name_dict.add(name.lower())\n",
    "\n",
    "#some characters have the same family name but different gender\n",
    "print(f'length of female name dict before:{len(female_name_dict)}')\n",
    "intersection_set = female_name_dict & male_name_dict \n",
    "female_name_dict = female_name_dict - intersection_set\n",
    "male_name_dict = male_name_dict - intersection_set\n",
    "print(f'length of female name dict after:{len(female_name_dict)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a2ce2f44-381a-4c22-948e-61ee29006ab9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shlykov, a hard-working taxi driver and Lyosha, a saxophonist, develop a bizarre love-hate relationship, and despite their prejudices, realize they aren't so different after all.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# data preprocessing\n",
    "# Set the stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Define a list of words representing females/males\n",
    "#from https://www.merriam-webster.com/thesaurus/\n",
    "female_words = set(['woman', 'girl', 'lady', 'female', 'daughter', 'mother', 'sister','girlfriend','maid','virgin','damsel','madame','senorita','princess','queen','her'])\n",
    "female_names_words = female_words | female_name_dict\n",
    "male_words = set(['man', 'boy', 'gentleman', 'male', 'son', 'father', 'brother','boyfriend','beau','husband','dude','lad','prince','king','him'])\n",
    "male_names_words = male_words | male_name_dict\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # lower the words and remove punctuation\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    # tokenize, replace words representing females with 'she' and males with 'he', and remove stopwords.\n",
    "    return ['she' if word in female_names_words else 'he' if word in male_names_words else word for word in text.split() if word not in stop_words]\n",
    "\n",
    "documents = []\n",
    "\n",
    "\n",
    "with open('data/plot_summaries.txt', 'r', encoding='utf-8') as file:\n",
    "    for line_number,line in enumerate(file):\n",
    "        _, text = line.split('\\t', 1)\n",
    "        processed_text = preprocess_text(text)\n",
    "        documents.append(processed_text)\n",
    "        if line_number< 1:\n",
    "            print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e655d6d2-22df-44cc-886e-cd759356559e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['shlykov',\n",
       " 'hardworking',\n",
       " 'taxi',\n",
       " 'driver',\n",
       " 'lyosha',\n",
       " 'saxophonist',\n",
       " 'develop',\n",
       " 'he',\n",
       " 'lovehate',\n",
       " 'relationship',\n",
       " 'despite',\n",
       " 'prejudices',\n",
       " 'realize',\n",
       " 'arent',\n",
       " 'he']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be479206-2e18-4ffd-962b-5b29dc6abb16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load the data adjectives.txt (extracted from the text in the extract_adj.ipynb)\n",
    "adjectives = []\n",
    "\n",
    "with open('data/adjectives.txt', 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        adjectives.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "81b967c6-e045-4650-8f0e-c9d6922ead9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train the word2vec model using the skip-gram architecture\n",
    "model = Word2Vec(documents, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# save the model\n",
    "model.save(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e12f767-0e1e-427c-947c-2604a739781b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# word to vector\n",
    "model = Word2Vec.load(\"word2vec.model\")\n",
    "adjectives = [word for word in adjectives if word in model.wv.key_to_index]\n",
    "adj_vectors = [model.wv[word] for word in adjectives]\n",
    "vector_she = model.wv['she']\n",
    "vector_he = model.wv['he']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d5b3a6c-c778-4dbe-bdca-3ecd14ab76fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "female_reference_vector = vector_she.reshape(1, -1)\n",
    "female_similarities = [cosine_similarity(female_reference_vector, vec.reshape(1, -1))[0][0] for vec in adj_vectors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c118a73c-aba5-4428-a56b-51a38c2f7bbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "male_reference_vector = vector_he.reshape(1, -1)\n",
    "male_similarities = [cosine_similarity(male_reference_vector, vec.reshape(1, -1))[0][0] for vec in adj_vectors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "671cb08f-bef8-4abb-9254-1de8b4f88569",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Female      Male\n",
      "metallic      0.050491  0.122352\n",
      "plague        0.036093  0.102109\n",
      "humanitarian  0.024778  0.100234\n",
      "undeterred    0.344810  0.341719\n",
      "nicer         0.439288  0.292362\n",
      "...                ...       ...\n",
      "whimper       0.009873  0.052732\n",
      "faraway       0.107892  0.137066\n",
      "calligraphy   0.082331  0.084284\n",
      "recreational  0.115089  0.113648\n",
      "biased       -0.012671  0.025984\n",
      "\n",
      "[13252 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "similaritie = pd.DataFrame({'Female':female_similarities,'Male':male_similarities})\n",
    "similaritie.index=adjectives\n",
    "print(similaritie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f382cc27-c6b8-44e8-926b-7dcb04a81812",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['longer', 'overjoyed', 'anymore', 'slept', 'relieved', 'shed',\n",
      "       'meantime', 'worried', 'nevertheless', 'distressed', 'broke', 'sorry',\n",
      "       'forgotten', 'sadly', 'somebody', 'reconnect', 'misunderstanding',\n",
      "       'apologizes', 'pleasurable', 'ruined', 'thinks', 'gidget', 'reconcile',\n",
      "       'none', 'confused', 'though', 'embarrassed', 'belong', 'want',\n",
      "       'changed', 'thrilled', 'ashamed', 'stunned', 'loved', 'wont', 'pleased',\n",
      "       'calm', 'neglected', 'depressed', 'somehow', 'mistake', 'touch',\n",
      "       'genuinely', 'sees', 'tired', 'bothered', 'comfortable', 'missed',\n",
      "       'surprise', 'neither', 'hug', 'excited', 'suitable', 'excitement',\n",
      "       'suddenly', 'worst', 'leave', 'knowing', 'afterwards', 'bother',\n",
      "       'devastated', 'almost', 'amazed', 'expected', 'élizabeth', 'pretending',\n",
      "       'unwell', 'already', 'staying', 'properly', 'happier', 'cant',\n",
      "       'otherwise', 'pretend', 'clearly', 'closer', 'hate', 'terribly',\n",
      "       'prettier', 'dejected', 'sober', 'desperately', 'uncomfortable',\n",
      "       'amends', 'forgive', 'babysitting', 'betrayed', 'please', 'embrace',\n",
      "       'unsure', 'unfortunately', 'yaman', 'nicer', 'forgetting', 'arguing',\n",
      "       'completely', 'expecting', 'happily', 'remarry', 'decent'],\n",
      "      dtype='object')\n",
      "Index(['somehow', 'longer', 'none', 'wont', 'stopped', 'betrayed', 'knowing',\n",
      "       'anymore', 'almost', 'save', 'unfortunately', 'broke', 'somebody',\n",
      "       'whole', 'fixed', 'mistake', 'barely', 'relieved', 'meantime',\n",
      "       'afterwards', 'suddenly', 'ruined', 'belong', 'whoever', 'let',\n",
      "       'tricked', 'whatever', 'otherwise', 'cant', 'pretending',\n",
      "       'nevertheless', 'leave', 'anywhere', 'close', 'impoundment', 'want',\n",
      "       'telling', 'impossible', 'ōba', 'meanwhile', 'shed', 'matter', 'coming',\n",
      "       'losing', 'finish', 'untie', 'stops', 'weak', 'though', 'realizes',\n",
      "       'saving', 'padlocked', 'planned', 'turn', 'sees', 'desperate',\n",
      "       'neither', 'turns', 'thinks', 'sorry', 'overjoyed', 'safe', 'therefore',\n",
      "       'properly', 'tells', 'dis', 'already', 'unknowingly', 'subsequently',\n",
      "       'touch', 'hiding', 'readily', 'desperately', 'stunned', 'sadly',\n",
      "       'badly', 'intermodal', 'pull', 'élizabeth', 'latter', 'thank', 'sooner',\n",
      "       'missed', 'calm', 'siddhappa', 'arguing', 'warn', 'gotten', 'gani',\n",
      "       'unnoticed', 'expected', 'vain', 'wherever', 'foolishly', 'ultimately',\n",
      "       'find', 'meant', 'mistakenly', 'promptly', 'worried'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "top_20_female_adj = similaritie['Female'].sort_values(ascending=False).head(100).index\n",
    "top_20_male_adj = similaritie['Male'].sort_values(ascending=False).head(100).index\n",
    "print(top_20_female_adj)\n",
    "print(top_20_male_adj)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
