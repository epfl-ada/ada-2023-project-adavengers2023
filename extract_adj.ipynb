{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3532f05b-d7a0-43db-9bd8-4dc993fac7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import Word2Vec\n",
    "import gensim\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6eee88c-e0d7-48b2-8a6d-c316788fa242",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "female_name_dict = []\n",
    "with open('data/female_name_dict.txt', 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        female_name_dict.append(line.strip())\n",
    "female_name_dict=set(female_name_dict)\n",
    "male_name_dict = []\n",
    "with open('data/male_name_dict.txt', 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        male_name_dict.append(line.strip())\n",
    "male_name_dict=set(male_name_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e761773b-62e7-4ce1-80f5-ee68d7da6801",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data preprocessing, very time-consuming\n",
    "# Set the stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Define a list of words representing females/males\n",
    "female_words = set(['woman', 'girl', 'lady', 'female', 'daughter', 'mother', 'sister','girlfriend','maid','virgin','damsel','madame','senorita','princess','queen','her'])\n",
    "female_names_words = female_words | female_name_dict\n",
    "male_words = set(['man', 'boy', 'gentleman', 'male', 'son', 'father', 'brother','boyfriend','beau','husband','dude','lad','prince','king','him'])\n",
    "male_names_words = male_words | male_name_dict\n",
    "remove_dict=(stop_words | female_names_words | male_names_words)\n",
    "#from https://www.merriam-webster.com/thesaurus/\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # lower the words and remove punctuation\n",
    "    text_token = word_tokenize(text)\n",
    "    tagged = pos_tag(text_token)\n",
    "    adjectives = [word for word, pos in tagged if (pos.startswith('JJ'))]\n",
    "    text = [word.lower() for word in adjectives if word.isalpha()]\n",
    "    # tokenize, replace words representing females with 'she' and males with 'he', and remove stopwords.\n",
    "    return [word for word in text if word not in remove_dict ]\n",
    "\n",
    "# 初始化一个空字符串用于存储结果\n",
    "long_string = \"\"\n",
    "documents=[]\n",
    "\n",
    "# load summaries\n",
    "with open('data/plot_summaries.txt', 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        text = line\n",
    "        documents.append(preprocess_text(text))\n",
    "documents = [word for sublist in documents for word in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fa57f7-5888-420c-87b6-ceec149df278",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# remove repetitive words\n",
    "print(len(documents))\n",
    "documents=list(set(documents))\n",
    "print(len(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "97afacc9-e0bd-464e-b12d-b28a0358554e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# to save time if you want to make change on the adj lists\n",
    "''' documents=[]\n",
    "with open('data/adjectives.txt', 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        # 使用 strip() 方法去除每行末尾的换行符并添加到列表\n",
    "        documents.append(line.strip())'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a1a4b581-a476-4945-bc17-f16414f2b274",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13335\n",
      "13322\n"
     ]
    }
   ],
   "source": [
    "# remove some words in case of incorrect classification\n",
    "lines = []\n",
    "\n",
    "# file from https://www.cs.cmu.edu/afs/cs/project/ai-repository/ai/areas/nlp/corpora/names/\n",
    "with open('data/female name.txt', 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        line=line.lower()\n",
    "        lines.append(line.strip())\n",
    "documents = set(documents)-(set(lines) & set(documents))\n",
    "\n",
    "lines = []\n",
    "with open('data/male name.txt', 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        line=line.lower()\n",
    "        lines.append(line.strip())\n",
    "documents = set(documents)-(set(lines) & set(documents))\n",
    "\n",
    "lines = []\n",
    "with open('data/names from movies.txt', 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        line=line.lower()\n",
    "        lines.append(line.strip())\n",
    "documents = set(documents)-(set(lines) & set(documents))\n",
    "print(len(documents))\n",
    "other_common_words = set(['child', 'orphan', 'baby', 'girls', 'lover', 'mute','child', 'orphan', 'bride', \n",
    "                          'baby', 'girls', 'lover', 'mute', 'housekeeper', 'cousin', 'neighbour', 'parent', \n",
    "                          'sibling', 'pregnant', 'housewife', 'relative', 'servant', 'waif', 'grandson', \n",
    "                          'stranger', 'courtesan', 'servant','cousin', 'neighbour', 'parent', 'sibling', \n",
    "                          'housewife','nurse', 'stepsister', 'housekeeper','grandson','servant','grandchildren',\n",
    "                          'relatives', 'uncles', 'orphans', 'childbirth', 'scoundrel', 'foreigner', 'stepfamily', \n",
    "                          'tuberculosis', 'mallaya', 'triplet', 'grandchildren', 'outcast', 'neighbours', 'huanhuan', \n",
    "                          'lakshmiammal', 'jaipal', 'himal', 'pasarian', 'leukemia'])\n",
    "documents = set(documents)-(set(documents) & set(other_common_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "598a5734-9f39-4d08-bf15-78e949799aca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save data\n",
    "with open('data/adjectives.txt', 'w', encoding='utf-8') as file:\n",
    "    for item in documents:\n",
    "        file.write(item + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
